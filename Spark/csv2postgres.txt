from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql import types as T

# Step 1: Initialize Spark session
spark = SparkSession.builder \
    .appName("CSV to PostgreSQL") \
    .config("spark.jars", "path/to/postgresql-42.2.20.jar") \
    .getOrCreate()

# Step 2: Read the CSV file into a DataFrame
csv_file_path = "path/to/your/file.csv"
df = spark.read.csv(csv_file_path, header=True, inferSchema=True)

# Step 3: Define PostgreSQL connection properties
postgres_url = "jdbc:postgresql://localhost:5432/your_database"
connection_properties = {
    "user": "your_username",
    "password": "your_password",
    "driver": "org.postgresql.Driver"
}

# Step 4: Write the DataFrame to PostgreSQL table
df.write.jdbc(url=postgres_url, table="your_table_name", mode="overwrite", properties=connection_properties)

# Stop the Spark session
spark.stop()